{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pugnu63W8Iry"
      },
      "source": [
        "Bhavesh Bhatt\n",
        "\n",
        "[**Link to my YouTube Channel**](https://www.youtube.com/BhaveshBhatt8791?sub_confirmation=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d6YB6Mh93Vc"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dzLKpmZICaWN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/fridh/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
            "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
            "2025-03-19 13:18:19.310338: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742386699.334228   11058 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742386699.341369   11058 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-03-19 13:18:19.365396: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sys import getsizeof"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZKNhx8x_1jq",
        "outputId": "86164e75-9fa4-419b-f086-0c4e893ddcd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.18.0\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VULHpvbVl0N"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ymcbpqPdLJxW"
      },
      "outputs": [],
      "source": [
        "def get_file_size(file_path):\n",
        "    size = os.path.getsize(file_path)\n",
        "    return size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_vfRLdF_LKUK"
      },
      "outputs": [],
      "source": [
        "def convert_bytes(size, unit=None):\n",
        "    if unit == \"KB\":\n",
        "        return print('File size: ' + str(round(size / 1024, 3)) + ' Kilobytes')\n",
        "    elif unit == \"MB\":\n",
        "        return print('File size: ' + str(round(size / (1024 * 1024), 3)) + ' Megabytes')\n",
        "    else:\n",
        "        return print('File size: ' + str(size) + ' bytes')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Importa Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import  pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"dataset.csv\", header=None)              # No header in your format\n",
        "dataset = df.iloc[:, :-1].to_numpy(dtype=np.float32)            # All but last column as float16\n",
        "labels_set = df.iloc[:, -1].to_numpy(dtype=str)                 # Last column as string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (583554, 13, 16, 1)\n",
            "Labels shape: (583554,)\n",
            "Input shape: (13, 16, 1)\n"
          ]
        }
      ],
      "source": [
        "dataset = dataset.reshape(dataset.shape[0], 13, 16, 1)\n",
        "input_shape = dataset[0].shape\n",
        "\n",
        "print(f\"Dataset shape: {dataset.shape}\")\n",
        "print(f\"Labels shape: {labels_set.shape}\")\n",
        "print(f\"Input shape: {input_shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set length: 373474\n",
            "Validation set length: 93369\n",
            "Testing set length: 116711\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(dataset, labels_set, test_size=0.2, random_state=42, stratify=labels_set)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
        "\n",
        "# Print the lengths of the training, validation, and testing sets.\n",
        "print(f\"Training set length: {len(x_train)}\")\n",
        "print(f\"Validation set length: {len(x_val)}\")\n",
        "print(f\"Testing set length: {len(x_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Calculate class weights.\n",
        "class_weight = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "dist_class_weight = dict(enumerate(class_weight))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes: ['Background_noise' 'Bus' 'Car' 'Motorcycle' 'Truck']\n"
          ]
        }
      ],
      "source": [
        "print(f\"Classes: {np.unique(labels_set)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class weights: {0: np.float64(2.303546536729785), 1: np.float64(0.8562873290458667), 2: np.float64(0.8566506869738744), 3: np.float64(0.9921999946866449), 4: np.float64(0.8177576334833208)}\n"
          ]
        }
      ],
      "source": [
        "print(f\"Class weights: {dist_class_weight}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Hot end code the labels.\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = to_categorical(label_encoder.fit_transform(y_train))\n",
        "y_test = to_categorical(label_encoder.fit_transform(y_test))\n",
        "y_val = to_categorical(label_encoder.fit_transform(y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59veuiEZCaW4"
      },
      "source": [
        "## Build & Compile the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "9ODch-OFCaW4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1742386715.484402   11058 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4201 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:09:00.0, compute capability: 7.5\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import InputLayer\n",
        "from tensorflow.keras.layers import SeparableConv2D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "model = keras.Sequential([\n",
        "    InputLayer(shape=input_shape),  # 25 frames, 16 channels\n",
        "\n",
        "    SeparableConv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "    SeparableConv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=2),\n",
        "\n",
        "    # Feature Pooling (Combining Max & Average Pooling)\n",
        "    GlobalAveragePooling2D(),\n",
        "\n",
        "    # Fully Connected Layer\n",
        "    Dense(32, activation=\"relu\", kernel_regularizer=l2(0.001)),\n",
        "    Dense(16, activation=\"relu\", kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.4),  # Dropout slightly reduced for stability\n",
        "\n",
        "    # Output Layer (Softmax for multi-class classification)\n",
        "    Dense(units=len(np.unique(labels_set)))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdOHE8CLNV1_",
        "outputId": "2abb88ee-6108-4a55-de69-1c910d6b1e56"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ separable_conv2d                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">137</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ separable_conv2d_1              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,736</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SeparableConv2D</span>)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ separable_conv2d                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m137\u001b[0m │\n",
              "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ separable_conv2d_1              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m4,736\u001b[0m │\n",
              "│ (\u001b[38;5;33mSeparableConv2D\u001b[0m)               │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m85\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,078</span> (31.55 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,078\u001b[0m (31.55 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,822</span> (30.55 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,822\u001b[0m (30.55 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> (1.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m256\u001b[0m (1.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Lhan11blCaW7"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['categorical_accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvwvpA64CaW_",
        "outputId": "57f84401-626e-4ec8-e461-b29068d30052"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1742386728.002176   11139 service.cc:148] XLA service 0x7b403c010310 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1742386728.002212   11139 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 2070 SUPER, Compute Capability 7.5\n",
            "2025-03-19 13:18:48.079327: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1742386728.378367   11139 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m  25/5836\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 7ms/step - categorical_accuracy: 0.2136 - loss: 1.9877 "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "I0000 00:00:1742386731.173076   11139 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m5836/5836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 8ms/step - categorical_accuracy: 0.3499 - loss: 1.3636 - val_categorical_accuracy: 0.3866 - val_loss: 1.3447\n",
            "Epoch 2/4\n",
            "\u001b[1m5836/5836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 7ms/step - categorical_accuracy: 0.3935 - loss: 1.2367 - val_categorical_accuracy: 0.4068 - val_loss: 1.3099\n",
            "Epoch 3/4\n",
            "\u001b[1m5836/5836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 7ms/step - categorical_accuracy: 0.4015 - loss: 1.2122 - val_categorical_accuracy: 0.4210 - val_loss: 1.2824\n",
            "Epoch 4/4\n",
            "\u001b[1m5836/5836\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6ms/step - categorical_accuracy: 0.4078 - loss: 1.1986 - val_categorical_accuracy: 0.4072 - val_loss: 1.3243\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b41feda5660>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train, y_train, epochs=4, validation_data=(x_val, y_val), class_weight=dist_class_weight, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "4n4_BRNKLRwo"
      },
      "outputs": [],
      "source": [
        "KERAS_MODEL_NAME = \"tf_model_mini.h5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "A_3Y3F4GBWud"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save(KERAS_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19sd1FJkCHID",
        "outputId": "df8e1537-f293-4579-916f-bc52aabc6e98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File size: 0.156 Megabytes\n"
          ]
        }
      ],
      "source": [
        "convert_bytes(get_file_size(KERAS_MODEL_NAME), \"MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "JIuCg2nyWsvs"
      },
      "outputs": [],
      "source": [
        "keras_model_size = get_file_size(KERAS_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_deKtkhCHMu",
        "outputId": "33e2fc11-f096-4076-a14b-9d7da30f661d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3648/3648 - 17s - 5ms/step - categorical_accuracy: 0.4097 - loss: 1.3271\n",
            "\n",
            "Test accuracy is 40.97%\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "print('\\nTest accuracy is {}%'.format(round(100*test_acc, 2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1BFE9lvwLfgv"
      },
      "source": [
        "# TF Lite Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ORAx4Yc7LjwM"
      },
      "outputs": [],
      "source": [
        "TF_LITE_MODEL_FILE_NAME = \"tf_lite_model.tflite\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NY57t7EwCW8P",
        "outputId": "2a240866-88ed-46cf-bca9-1bdf5276a155"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmppne5pk6c/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmppne5pk6c/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at '/tmp/tmppne5pk6c'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 13, 16, 1), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  135523384691872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135523386080448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135523384689936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135523384698736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135523384700144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135523384697680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135523384698208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135523384697504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135523384701376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135523384701728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135523384703488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135523384698032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135523384689408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135523384704368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135523384689232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135523385020960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135523385020432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135523385018320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135523385022720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135523385020608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1742386911.542371   11058 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1742386911.542393   11058 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "2025-03-19 13:21:51.542781: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmppne5pk6c\n",
            "2025-03-19 13:21:51.544280: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
            "2025-03-19 13:21:51.544296: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmppne5pk6c\n",
            "I0000 00:00:1742386911.555158   11058 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\n",
            "2025-03-19 13:21:51.557100: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
            "2025-03-19 13:21:51.616117: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmppne5pk6c\n",
            "2025-03-19 13:21:51.633742: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 90966 microseconds.\n"
          ]
        }
      ],
      "source": [
        "tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = tf_lite_converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZxnt1IsCXBb",
        "outputId": "68b429c5-54a9-47f4-f452-473c40cf958f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "37328"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tflite_model_name = TF_LITE_MODEL_FILE_NAME\n",
        "open(tflite_model_name, \"wb\").write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtIdP296CXFl",
        "outputId": "6c308c2d-f657-4c7e-af58-d7454d87fa92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File size: 36.453 Kilobytes\n"
          ]
        }
      ],
      "source": [
        "convert_bytes(get_file_size(TF_LITE_MODEL_FILE_NAME), \"KB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "CRScWYLIWmkI"
      },
      "outputs": [],
      "source": [
        "tflite_file_size = get_file_size(TF_LITE_MODEL_FILE_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_gttI3-M45M"
      },
      "source": [
        "# Check Input Tensor Shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJXJuGLFGfjB",
        "outputId": "064467be-2de5-4e5e-fbdb-5b61c91b9826"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Shape: [ 1 13 16  1]\n",
            "Input Type: <class 'numpy.float32'>\n",
            "Output Shape: [1 5]\n",
            "Output Type: <class 'numpy.float32'>\n"
          ]
        }
      ],
      "source": [
        "interpreter = tf.lite.Interpreter(model_path = TF_LITE_MODEL_FILE_NAME)\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(\"Input Shape:\", input_details[0]['shape'])\n",
        "print(\"Input Type:\", input_details[0]['dtype'])\n",
        "print(\"Output Shape:\", output_details[0]['shape'])\n",
        "print(\"Output Type:\", output_details[0]['dtype'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpvft4cnsf/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpvft4cnsf/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at '/tmp/tmpvft4cnsf'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 13, 16, 1), dtype=tf.float32, name='input_layer')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  135522732238528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135522732243984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135522732281872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135522732289792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135522732290496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135522732286448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135522732288736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135522732363968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135522732365024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135522732364144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135522732371008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135522732372768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135522732370304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135522732371536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135522732483584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135522732480416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135522732486400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135522732487104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135522732677904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  135522732672800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "W0000 00:00:1742386913.144739   11058 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1742386913.144757   11058 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "2025-03-19 13:21:53.144970: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmpvft4cnsf\n",
            "2025-03-19 13:21:53.146056: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
            "2025-03-19 13:21:53.146072: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /tmp/tmpvft4cnsf\n",
            "2025-03-19 13:21:53.158438: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
            "2025-03-19 13:21:53.221655: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /tmp/tmpvft4cnsf\n",
            "2025-03-19 13:21:53.239164: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 94195 microseconds.\n"
          ]
        }
      ],
      "source": [
        "# Load your existing model\n",
        "model = tf.keras.models.load_model('tf_model_mini.h5')\n",
        "\n",
        "# Convert the model to TensorFlow Lite format with quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_types = [tf.uint8]\n",
        "\n",
        "# Ensure that the input and output types are uint8\n",
        "def representative_dataset_gen():\n",
        "    for i in range(len(x_test)):\n",
        "        # Get sample input data as a numpy array in a method of your choosing\n",
        "        yield [x_test[i]]\n",
        "\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "tflite_quant_model = converter.convert()\n",
        "\n",
        "# Save the quantized model\n",
        "with open('pipeline_int8_model_data.tflite', 'wb') as f:\n",
        "    f.write(tflite_quant_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Could not open 'quantized_model.tflite'.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load and test the quantized model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m interpreter \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInterpreter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquantized_model.tflite\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m interpreter\u001b[38;5;241m.\u001b[39mallocate_tensors()\n\u001b[1;32m      5\u001b[0m input_details \u001b[38;5;241m=\u001b[39m interpreter\u001b[38;5;241m.\u001b[39mget_input_details()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:470\u001b[0m, in \u001b[0;36mInterpreter.__init__\u001b[0;34m(self, model_path, model_content, experimental_delegates, num_threads, experimental_op_resolver_type, experimental_preserve_all_tensors, experimental_disable_delegate_clustering, experimental_default_delegate_latest_features)\u001b[0m\n\u001b[1;32m    464\u001b[0m custom_op_registerers_by_name \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    465\u001b[0m     x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_custom_op_registerers \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    466\u001b[0m ]\n\u001b[1;32m    467\u001b[0m custom_op_registerers_by_func \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    468\u001b[0m     x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_custom_op_registerers \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    469\u001b[0m ]\n\u001b[0;32m--> 470\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpreter \u001b[38;5;241m=\u001b[39m \u001b[43m_interpreter_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateWrapperFromFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mop_resolver_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_op_registerers_by_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_op_registerers_by_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperimental_preserve_all_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperimental_disable_delegate_clustering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperimental_default_delegate_latest_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpreter:\n\u001b[1;32m    481\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFailed to open \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model_path))\n",
            "\u001b[0;31mValueError\u001b[0m: Could not open 'quantized_model.tflite'."
          ]
        }
      ],
      "source": [
        "# Load and test the quantized model\n",
        "interpreter = tf.lite.Interpreter(model_path='quantized_model.tflite')\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Test the TensorFlow Lite model on random data from x_test\n",
        "input_shape = input_details[0]['shape']\n",
        "output_shape = output_details[0]['shape']\n",
        "\n",
        "# Test the TensorFlow Lite model on random data from x_test\n",
        "input_data = x_test[np.random.choice(x_test.shape[0], 1)]\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "interpreter.invoke()\n",
        "tflite_results = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "print(\"TensorFlow Lite model output:\", tflite_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_X-k46vMzAt"
      },
      "source": [
        "# Resize Tensor Shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_test = x_test.astype(np.float32)\n",
        "y_test = y_test.astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6wo8RNFGpXw",
        "outputId": "638ebb8a-763c-462a-e0ee-dae5e22b99a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input Shape: [999  13  16   1]\n",
            "Input Type: <class 'numpy.float32'>\n",
            "Output Shape: [231   5]\n",
            "Output Type: <class 'numpy.float32'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
          ]
        }
      ],
      "source": [
        "interpreter.resize_tensor_input(input_details[0]['index'], x_test.shape)\n",
        "interpreter.resize_tensor_input(output_details[0]['index'], y_test.shape)\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(\"Input Shape:\", input_details[0]['shape'])\n",
        "print(\"Input Type:\", input_details[0]['dtype'])\n",
        "print(\"Output Shape:\", output_details[0]['shape'])\n",
        "print(\"Output Type:\", output_details[0]['dtype'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsv7ROq8Gf0f",
        "outputId": "b3f12843-d88a-4da9-a97e-30cf8f50ac7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "SM1alowAHy2d"
      },
      "outputs": [],
      "source": [
        "test_imgs_numpy = np.array(x_test, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JBxCCNTTnft",
        "outputId": "5729097a-56eb-4f67-bec4-a555328bf5e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "test_imgs_numpy.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wm4bxTIwHErB",
        "outputId": "7d9bd4ea-de68-4bf7-fcb4-38b4380d3ebe"
      },
      "outputs": [],
      "source": [
        "interpreter.set_tensor(input_details[0]['index'], test_imgs_numpy)\n",
        "interpreter.invoke()\n",
        "tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
        "prediction_classes = np.argmax(tflite_model_predictions, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRKoF30HIZP2"
      },
      "outputs": [],
      "source": [
        "# Convert y_test from one-hot encoded format to label format\n",
        "y_test_labels = np.argmax(y_test, axis=1)[:len(prediction_classes)]\n",
        "acc = accuracy_score(prediction_classes, y_test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZIF6OenI_5i",
        "outputId": "17d43528-4ef4-44c6-c0e7-b7e2e2a9de39"
      },
      "outputs": [],
      "source": [
        "print('Test accuracy TFLITE model is {}%'.format(round(100*acc, 2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tNSVxOHWfPY",
        "outputId": "2cce54ba-695e-48eb-a2ca-723622f89b35"
      },
      "outputs": [],
      "source": [
        "tflite_file_size/keras_model_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6CZhJbUY44n"
      },
      "source": [
        "# TF Lite Model Float 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhpWvf2KY-va"
      },
      "outputs": [],
      "source": [
        "TF_LITE_MODEL_FLOAT_16_FILE_NAME = \"tf_lite_float_16_model.tflite\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzBgcOfGY-32",
        "outputId": "f8a9b0ca-ab41-47c6-8019-467b92b00d91"
      },
      "outputs": [],
      "source": [
        "tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tf_lite_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tf_lite_converter.target_spec.supported_types = [tf.float16]\n",
        "tflite_model = tf_lite_converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-OTCqGzZGkd",
        "outputId": "4ffde011-3843-4540-950a-f387e007ab48"
      },
      "outputs": [],
      "source": [
        "tflite_model_name = TF_LITE_MODEL_FLOAT_16_FILE_NAME\n",
        "open(tflite_model_name, \"wb\").write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLWOTWT-ZGnD",
        "outputId": "ec695991-d18b-41e1-eeed-2714fb860abc"
      },
      "outputs": [],
      "source": [
        "convert_bytes(get_file_size(TF_LITE_MODEL_FLOAT_16_FILE_NAME), \"KB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s70HjhmYZGqf"
      },
      "outputs": [],
      "source": [
        "tflite_float_16_file_size = get_file_size(TF_LITE_MODEL_FLOAT_16_FILE_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roa0xXtdZGsq",
        "outputId": "964f8c34-b0ca-40b0-8ad0-4d735878b62a"
      },
      "outputs": [],
      "source": [
        "tflite_float_16_file_size/keras_model_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFijAawdZeyA",
        "outputId": "2487cf93-d2f4-403c-8c3e-ebc6ca77136d"
      },
      "outputs": [],
      "source": [
        "tflite_float_16_file_size/tflite_file_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXrlI_NfZyZr"
      },
      "source": [
        "# TF Lite Size Quantized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CoTxxLp2Ze0b"
      },
      "outputs": [],
      "source": [
        "TF_LITE_SIZE_QUANT_MODEL_FILE_NAME = \"tf_lite_quant_model.tflite\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLzVy5BEZ7dK",
        "outputId": "59992e93-2750-40af-8287-02ee510bd8e4"
      },
      "outputs": [],
      "source": [
        "tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tf_lite_converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
        "tflite_model = tf_lite_converter.convert()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFx8bVTGZ7fk",
        "outputId": "84ce79aa-3273-41bf-9929-e2190ea23a49"
      },
      "outputs": [],
      "source": [
        "tflite_model_name = TF_LITE_SIZE_QUANT_MODEL_FILE_NAME\n",
        "open(tflite_model_name, \"wb\").write(tflite_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNBKgf-XZ7iN",
        "outputId": "4cf2a6c8-dcfd-4974-efce-9cef4723ac8b"
      },
      "outputs": [],
      "source": [
        "convert_bytes(get_file_size(TF_LITE_SIZE_QUANT_MODEL_FILE_NAME), \"KB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRpw-azsZ7lD"
      },
      "outputs": [],
      "source": [
        "tflite_float_quant_file_size = get_file_size(TF_LITE_SIZE_QUANT_MODEL_FILE_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEUM1ApdZe3T",
        "outputId": "24522d6c-8cfe-4fdb-fc68-72ea2841e45d"
      },
      "outputs": [],
      "source": [
        "tflite_float_quant_file_size/keras_model_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIdMzivLY-7J",
        "outputId": "0b176cd9-cd54-4dc7-af70-184624016dba"
      },
      "outputs": [],
      "source": [
        "tflite_float_quant_file_size/ tflite_float_16_file_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjEiZWfvaoGW"
      },
      "source": [
        "# Accuracy of the Quantized Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBIKxBccatZj"
      },
      "source": [
        "# Check Input Tensor Shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMVMXOHpar5z",
        "outputId": "24b50382-8c21-4850-f8ff-6a770224ff31"
      },
      "outputs": [],
      "source": [
        "interpreter = tf.lite.Interpreter(model_path = TF_LITE_SIZE_QUANT_MODEL_FILE_NAME)\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(\"Input Shape:\", input_details[0]['shape'])\n",
        "print(\"Input Type:\", input_details[0]['dtype'])\n",
        "print(\"Output Shape:\", output_details[0]['shape'])\n",
        "print(\"Output Type:\", output_details[0]['dtype'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqvlZxiSa2I2"
      },
      "source": [
        "# Resize Tensor Shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQDZyidSar8s",
        "outputId": "a9a89572-e147-43f6-c6fd-e79c8c45f791"
      },
      "outputs": [],
      "source": [
        "interpreter.resize_tensor_input(input_details[0]['index'], x_test.shape)\n",
        "interpreter.resize_tensor_input(output_details[0]['index'], y_test.shape)\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(\"Input Shape:\", input_details[0]['shape'])\n",
        "print(\"Input Type:\", input_details[0]['dtype'])\n",
        "print(\"Output Shape:\", output_details[0]['shape'])\n",
        "print(\"Output Type:\", output_details[0]['dtype'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCGHzlitar_r",
        "outputId": "6958ce58-b53f-47b6-debc-e59922d2824c"
      },
      "outputs": [],
      "source": [
        "x_test.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wFRpCMfa6Xx"
      },
      "outputs": [],
      "source": [
        "test_imgs_numpy = np.array(x_test, dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOY13_oIa6aR",
        "outputId": "fa24dfbe-f858-40f6-e42c-ef2a58ff8b91"
      },
      "outputs": [],
      "source": [
        "interpreter.set_tensor(input_details[0]['index'], test_imgs_numpy)\n",
        "interpreter.invoke()\n",
        "tflite_model_predictions = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(\"Prediction results shape:\", tflite_model_predictions.shape)\n",
        "prediction_classes = np.argmax(tflite_model_predictions, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmcpKhSsa6di"
      },
      "outputs": [],
      "source": [
        "# Convert y_test from one-hot encoded format to label format\n",
        "y_test_labels = np.argmax(y_test, axis=1)[:len(prediction_classes)]\n",
        "acc = accuracy_score(prediction_classes, y_test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1fwddHqa6gw",
        "outputId": "1ea25d24-47a9-4406-b83f-b62abbf75472"
      },
      "outputs": [],
      "source": [
        "print('Test accuracy TFLITE Quantized model is {}%'.format(round(100*acc, 2)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "tflite-notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
