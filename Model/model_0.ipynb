{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Vehicle Classification Model\n",
        "\n",
        "This file contains the code for creatiing, training, and compressing the CNN used for the thesis project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/seconds_per_frame:0.50,overlap:0.25,mfccs:40_.csv\"\n",
        "INPUT_SHAPE = (40, 16, 1)\n",
        "\n",
        "MODEL_NAME = \"cnn\"\n",
        "\n",
        "GENERATE_KERAS_MODLE = False\n",
        "KERAS_MODEL_NAME = f\"{MODEL_NAME}.h5\"  # Try using .keras instead.\n",
        "\n",
        "TF_LITE_MODEL_FILE_NAME = f\"{MODEL_NAME}.tflite\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4d6YB6Mh93Vc"
      },
      "source": [
        "## Imports\n",
        "\n",
        "Place all imports in this section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dzLKpmZICaWN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import (\n",
        "    Flatten, Dense, Conv2D, MaxPooling2D, BatchNormalization, Dropout, \n",
        "    InputLayer, GlobalAveragePooling2D\n",
        ")\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZKNhx8x_1jq",
        "outputId": "e564096b-b86e-4512-c0b2-35aed80e84dc"
      },
      "outputs": [],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Se2Y1iRrzxT"
      },
      "outputs": [],
      "source": [
        "# Modify GPU memory allocator to try to prevent full GPU memory.\n",
        "# This can in some cases be counter productive!\n",
        "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VULHpvbVl0N"
      },
      "source": [
        "# Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymcbpqPdLJxW"
      },
      "outputs": [],
      "source": [
        "def get_file_size(file_path):\n",
        "    size = os.path.getsize(file_path)\n",
        "    return size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vfRLdF_LKUK"
      },
      "outputs": [],
      "source": [
        "def convert_bytes(size, unit=None):\n",
        "    if unit == \"KB\":\n",
        "        return print('File size: ' + str(round(size / 1024, 3)) + ' Kilobytes')\n",
        "    elif unit == \"MB\":\n",
        "        return print('File size: ' + str(round(size / (1024 * 1024), 3)) + ' Megabytes')\n",
        "    else:\n",
        "        return print('File size: ' + str(size) + ' bytes')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArL366zjd4Xc"
      },
      "source": [
        "# Importa Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieeCS0L0d4Xd"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(DATASET_PATH, header=None)                     # Note that these should be no header present.\n",
        "dataset = df.iloc[:, :-1].to_numpy(dtype=np.float32)            # All but last column as float32 (required by MCU)\n",
        "labels_set = df.iloc[:, -1].to_numpy(dtype=str)                 # Last column as string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIH5p603d4Xd",
        "outputId": "bc4027f5-3dd3-4b1b-dbb6-4c6114530018"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.reshape(dataset.shape[0], INPUT_SHAPE[0], INPUT_SHAPE[1], INPUT_SHAPE[2])\n",
        "\n",
        "print(f\"Dataset shape: {dataset.shape}\")\n",
        "print(f\"Labels shape: {labels_set.shape}\")\n",
        "print(f\"Input shape: {INPUT_SHAPE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap-ud1Jbd4Xe",
        "outputId": "7491ac03-1445-4b7f-a5c6-73a509b617fa"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(dataset, labels_set, test_size=0.2, random_state=42, stratify=labels_set)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
        "\n",
        "# Print the lengths of the training, validation, and testing sets.\n",
        "print(f\"Training set length: {len(x_train)}\")\n",
        "print(f\"Validation set length: {len(x_val)}\")\n",
        "print(f\"Testing set length: {len(x_test)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2p_MTiid4Xf"
      },
      "outputs": [],
      "source": [
        "# Calculate class weights (based on training data).\n",
        "class_weight = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "dist_class_weight = dict(enumerate(class_weight))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10khbK5Qd4Xf",
        "outputId": "87dcb6fb-b159-42aa-c0fb-bf15d873c5e9"
      },
      "outputs": [],
      "source": [
        "print(f\"Classes: {np.unique(labels_set)}\")\n",
        "print(f\"Class weights: {dist_class_weight}\")\n",
        "\n",
        "# Print out the amount of each class.\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print(f\"Training class distribution: {dict(zip(unique, counts))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEXSIf2Qd4Xh"
      },
      "outputs": [],
      "source": [
        "# Hot end code the labels.\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = to_categorical(label_encoder.fit_transform(y_train))\n",
        "y_test = to_categorical(label_encoder.fit_transform(y_test))\n",
        "y_val = to_categorical(label_encoder.fit_transform(y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59veuiEZCaW4"
      },
      "source": [
        "## Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCxFDXesrzxc"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8preOUYXd4Xk"
      },
      "outputs": [],
      "source": [
        "def compileModel(model, learning_rate = 0.001):\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "        metrics=['categorical_accuracy']\n",
        "    )\n",
        "    model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Wm8zfrvveeJ"
      },
      "outputs": [],
      "source": [
        "# Print training history\n",
        "# Function used for printing two plots, one for accuracy and one for loss.\n",
        "# To be used with the history object from the fit method\n",
        "def printHistory(history):\n",
        "  # Collect the number of epochs run based on the amount of loss value under history.\n",
        "  epochs = len(history.history['loss'])\n",
        "\n",
        "  epochrange = range(1, epochs + 1)\n",
        "  train_acc = history.history['categorical_accuracy']\n",
        "  val_acc = history.history['val_categorical_accuracy']\n",
        "\n",
        "  train_loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  plt.plot(epochrange, train_acc, 'bo', label='Training acc')\n",
        "  plt.plot(epochrange, val_acc, 'b', label='Validation acc')\n",
        "  plt.title('Training and validation accuracy (modell 1)')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  plt.plot(epochrange, train_loss, 'bo', label='Training loss')\n",
        "  plt.plot(epochrange, val_loss, 'b', label='Validation loss')\n",
        "  plt.title('Training and validation loss (modell 1)')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PF_VyRPKrzxd"
      },
      "outputs": [],
      "source": [
        "def printConfusionMatrix(model, x_test, y_test, labels_set):\n",
        "    y_train_int = np.argmax(y_train, axis=1)  # Convert one-hot to integer labels for y_train\n",
        "    y_test_int = np.argmax(y_test, axis=1)  # Convert one-hot to integer labels for y_test\n",
        "\n",
        "    y_pred_prob = model.predict(x_test)\n",
        "\n",
        "    y_pred = np.argmax(y_pred_prob, axis=1)  # Convert softmax probabilities to class indices\n",
        "\n",
        "    # Ensure that the labels are in 1D arrays (class indices) before passing to confusion_matrix\n",
        "    print(f\"y_train_int shape: {y_train_int.shape}\")\n",
        "    print(f\"y_test_int shape: {y_test_int.shape}\")\n",
        "    print(f\"y_pred shape: {y_pred.shape}\")\n",
        "\n",
        "    # Define your class labels (ensure they match the number of classes)\n",
        "    class_names = np.unique(labels_set)  # Assuming labels_set contains class names\n",
        "\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_test_int, y_pred)\n",
        "\n",
        "    # Visualize the confusion matrix with proper labels\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FztgpcUvtoHU"
      },
      "outputs": [],
      "source": [
        "# Fit model function used for convinience when fitting the model multiple times\n",
        "def fitModel(model, x_train, y_train, x_val, y_val, epochs, doPrintHistory, class_weight, verbose, batch_size):\n",
        "\n",
        "    # Define early stopping callback.\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "    history = model.fit(\n",
        "        x=x_train,\n",
        "        y=y_train,\n",
        "        validation_data=(x_val, y_val),\n",
        "        epochs=epochs,\n",
        "        verbose=verbose,\n",
        "        class_weight=class_weight,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=[early_stopping],\n",
        "    )\n",
        "    # Print history\n",
        "    if doPrintHistory: printHistory(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_tflite_model(model_path, x_test, y_test):\n",
        "\n",
        "  interpreter = tf.lite.Interpreter(model_path)\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  input_details = interpreter.get_input_details()\n",
        "  output_details = interpreter.get_output_details()\n",
        "\n",
        "  predictions = []\n",
        "  for i in range(len(x_test)):\n",
        "    # Set the input tensor.\n",
        "    interpreter.set_tensor(input_details[0]['index'], [x_test[i]])\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Get the output tensor.\n",
        "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "    predictions.append(output_data)\n",
        "\n",
        "  # Convert predictions to class labels\n",
        "  predicted_labels = [np.argmax(prediction[0]) for prediction in predictions]\n",
        "  true_labels = [np.argmax(label) for label in y_test]\n",
        "\n",
        "  # Calculate accuracy\n",
        "  correct_predictions = sum([1 for true, predicted in zip(true_labels, predicted_labels) if true == predicted])\n",
        "  accuracy = correct_predictions / len(true_labels)\n",
        "\n",
        "  # Print the accuracy\n",
        "  print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "  # Print a classification report\n",
        "  print(classification_report(true_labels, predicted_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TYhCf6krzxd"
      },
      "source": [
        "### Create, train, compile, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ODch-OFCaW4"
      },
      "outputs": [],
      "source": [
        "model = keras.Sequential([\n",
        "    InputLayer(shape=INPUT_SHAPE),\n",
        "\n",
        "    Conv2D(filters=32, kernel_size=3, activation=\"relu\", padding='same'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(),\n",
        "\n",
        "    Conv2D(filters=32, kernel_size=3, activation=\"relu\", padding='same'),\n",
        "    MaxPooling2D(),\n",
        "\n",
        "    # Feature Pooling (Combining Max & Average Pooling)\n",
        "    Flatten(),\n",
        "\n",
        "    # Fully Connected Layer\n",
        "    Dense(32, activation=\"relu\", kernel_regularizer=l2(0.001)),\n",
        "\n",
        "    # Output Layer (Softmax for multi-class classification)\n",
        "    Dense(units=len(np.unique(labels_set)), activation=\"softmax\") # Softmax barely increase size.\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "xvwvpA64CaW_",
        "outputId": "01ae9c32-9bf0-4ce0-bb48-5c51c0afb89c"
      },
      "outputs": [],
      "source": [
        "compileModel(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Z7XNMH5Lrzxd",
        "outputId": "3305465a-1651-49e3-d168-caa978d6a4c7"
      },
      "outputs": [],
      "source": [
        "fitModel(model, x_train, y_train, x_val, y_val, 6, True, dist_class_weight, 1, 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkVSBCHvrzxe",
        "outputId": "a79fd00d-4eef-481b-9d82-a25b5c5b5b4a"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the test set.\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "id": "Wh_ETmEErzxe",
        "outputId": "e17a65c0-ce2d-4873-9cdf-7dcdb9831108"
      },
      "outputs": [],
      "source": [
        "printConfusionMatrix(model, x_test, y_test, labels_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijrhH7herzxe"
      },
      "source": [
        "# Save & Compress model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjEc-azSrzxe"
      },
      "source": [
        "### Keras Model\n",
        "\n",
        "Generating the Keras model is not required, thus the boolean check."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4n4_BRNKLRwo",
        "outputId": "a1b5a9be-5fe9-4fc2-d61c-a73cc8718cbc"
      },
      "outputs": [],
      "source": [
        "if GENERATE_KERAS_MODLE:\n",
        "    model.save(KERAS_MODEL_NAME)\n",
        "    print(\"Keras model saved: \", KERAS_MODEL_NAME)\n",
        "    convert_bytes(get_file_size(KERAS_MODEL_NAME), \"KB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP9VcO0Krzxg"
      },
      "source": [
        "### TF Lite model\n",
        "\n",
        "The TF Lite model is the main model to be used. This is where compression happens and thus also makes it important to test once again after compression. Once done, it's transformed into a CPP file to be implemented into pico-tfmicro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NY57t7EwCW8P",
        "outputId": "b972b38d-b543-4443-9c72-03223e3d4cf9"
      },
      "outputs": [],
      "source": [
        "# Convert into TFLite model.\n",
        "tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# Apply optomizations.\n",
        "tf_lite_converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tf_lite_converter.target_spec.supported_types = [tf.float32]\n",
        "\n",
        "# Grab model and save it.\n",
        "tflite_model = tf_lite_converter.convert()\n",
        "tflite_model_name = TF_LITE_MODEL_FILE_NAME\n",
        "open(tflite_model_name, \"wb\").write(tflite_model)\n",
        "\n",
        "print(\"TFLite model saved: \", TF_LITE_MODEL_FILE_NAME)\n",
        "convert_bytes(get_file_size(TF_LITE_MODEL_FILE_NAME), \"KB\")\n",
        "\n",
        "# Print model input and output shape for debugging.\n",
        "interpreter = tf.lite.Interpreter(model_path=TF_LITE_MODEL_FILE_NAME)\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "print(\"Input Shape:\", input_details[0]['shape'])\n",
        "print(\"Input Type:\", input_details[0]['dtype'])\n",
        "print(\"Output Shape:\", output_details[0]['shape'])\n",
        "print(\"Output Type:\", output_details[0]['dtype'])\n",
        "\n",
        "# Evaluate the TFLite model.\n",
        "evaluate_tflite_model(TF_LITE_MODEL_FILE_NAME, x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cavoNO3Ipgla"
      },
      "outputs": [],
      "source": [
        "# Save the TF Lite model as a C++ array using xxd.\n",
        "# This is required to implement the model using pico-tfmicro.\n",
        "# Note that the file size from this is larger than the tflite file size,\n",
        "# but won't increase the story size of the model when implemented in C++.\n",
        "!xxd -i {TF_LITE_MODEL_FILE_NAME} > {MODEL_NAME}.cpp"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
